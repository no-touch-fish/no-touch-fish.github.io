<html>
<head>
	<meta  http-equiv="Content-Type" content="text/html; charset=utf-8" />
	<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1.0, user-scalable=0" />
	<link rel="stylesheet" type="text/css" href="utils/bootstrap.min.css"/>
  <script language="javascript" src="utils/jquery.min.js"></script>
	<script language="javascript" src="utils/bootstrap.min.js"></script>
  <!-- -->
  <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css"/>
	<link rel="stylesheet" type="text/css" href="utils/cssReset.css"/>
  <link rel="stylesheet" type="text/css" href="utils/css_layout.css"/>
	<title>Junsheng Huang</title>
  <!-- 搜索引擎优化stuff -->
  <meta name="description"
    content="Academic website for Junsheng Huang.">
	<meta name="keywords" content="Junsheng Huang,黄俊昇,UIUC,ZJU,,University of Illinois Urbana-Champaign, Zhejiang University">
  

</head>



<body>
  <div id="sidebar">
    <!--<a href="resources/me_high_res.jpg" target="_blank"><img class='me' src="resources/me_low_res.jpg"></img></a> -->
    <br/>
    <div class="info">
      <h2 class="name">Junsheng Huang (He/Him)</h2>
      <h2 class="name_chinese">黄俊昇</h2>
      <h2 class="email">jh103@illinois.edu</h2>
      <h2 class="email">junsheng.21@intl.zju.edu.cn</h2> 
      <h2 class="email">ZJU / UIUC</h2>
      <h2 class="link">
        <a href="https://github.com/no-touch-fish" target="_blank">[GitHub]</a>
      </h2>
    </div>
    <div id="navigation">
      <a class="nav_item" href="./index.html">
        <i class="icon icon-home icon-white"></i> &nbsp; About
      </a>
      <a class="nav_item" href="./projects.html#projects">
        <i class="icon icon-th-large icon-white"></i> &nbsp; Projects & Awards
      </a>
      <a class="nav_item" href="./research.html#research">
        <i class="icon icon-th-large icon-white"></i> &nbsp; Research
      </a>
      <a class="nav_item" href="./research.html#publications">
        <i class="icon icon-th icon-white"></i> &nbsp; Publications
      </a>
      <a class="nav_item" href="./teaching.html#teaching">
        <i class="icon icon-user icon-white"></i> &nbsp; Teaching / Talks
      </a>
    </div>
  </div>

<style type="text/css">
  #main{
    background: #f7f7f7;
  }
  #main > div.publications > ol > li{
    background: white;
    box-shadow: 2px 5px 5px #c9c9c9;
    margin-bottom: 10px;
    padding: 20px;
  }
  #main div.img{
    padding: 20px;
    text-align: center;
    padding-right: 150px;
  }
  #main div.img > div.img_caption{
    font-weight: 450;
    font-size: 1.1em;
    line-height: 40px;
  }
</style>
<div id="main">

  <div class="title">
    <a class="title_link" id="research" href="#research"> Research Experience</a>
  </div>
  <div class="content">
  <!-- Federal KAG -->
  <div class="project">
    <div class="project-title">
      Federated Knowledge-Augmented Generation
      <span class="location">ZJU-UIUC Institute, China</span>
    </div>
    <div class="project-role">
      Advisor: Qiang Zhang (ZJUI Professor)
      <span class="date">Jun 2024 - Current</span>
    </div>
    <ul class="project-details">
      <li><strong>Motivation:</strong> The goal is to develop a personalized and privacy-preserving text generation systems based on large langauge models. 
        Federated Learning enables training machine learning models across multiple devices or servers without sharing raw data. Knowledge-Augmented Generation (KAG) combines retrieval and generation components to enhance text generation tasks.
      </li>
	  <div class="linebreak"></div>
	</ul>
  </div>
  <!-- Teaching Large Language Models to Handle the Composition of Multiple Problems Simultaneously -->
  <div class="project">
    <div class="project-title">
      Teaching Large Language Models to Handle the Composition of Multiple Problems Simultaneously
      <span class="location">Remote</span>
    </div>
    <div class="project-role">
      Advisor: May Fung (HKUST Professor)
      <span class="date">Jun 2024 - Current</span>
    </div>
    <ul class="project-details">
      <li><strong>Motivation:</strong> Current evaluation of LLM hallucination only focus on single problem setting. 
        Because of this, we investigate how LLM perform and deal with hallucination under multiple problem setting, where it need to response to multiple questions simultaneously.
      </li>
      <li><strong>Result:</strong> We propose a novel fine-tune method called  Multiple Answers and Confidence Stepwise Tuning (<strong>MAC-Tuning</strong>) with up to 12% improvement comparing with baseline and up to 40\% improvement comparing with Zero-shot model under multiple problem setting.
      </li>
      <li><strong>Contribution:</strong> I conduct the entire process of data collection and building the project code. 
        At the same time,  I tested various approaches, like LLM-Judge and keyword extraction, to assess the accuracy of LLM-generated outputs. 
        Furthermore, I experimented diverse evaluation metrics including accuracy, AP score and MAP to comprehensively evaluate model performance.
      </li>
	  <div class="linebreak"></div>
	</ul>
  </div>
  <!-- Simple Random Augmentation -->
  <div class="project">
    <div class="project-title">
      Random Augmentations Cheaply Break LLM Safety Alignment
      <span class="location">UIUC, America</span>
    </div>
    <div class="project-role">
      Advisor: Gagandeep Singh (UIUC Professor), Jason Vega (UIUC Ph.D)
      <span class="date">Jun 2024 - Dec 2024</span>
    </div>
    <ul class="project-details">
      <li><strong>Motivation:</strong> Current jailbreak methods are rather costly or involve a non-trivial amount of creativity and effort. 
        Since that, we investigate how simple random augmentations to the input prompt affect safety alignment effectiveness in LLMs from different dimensions, 
        including augmentation type, model size, quantization, fine-tuning-based defenses and decoding strategies.
      </li>
      <li><strong>Result:</strong> We show that low-resource and unsophisticated attackers can significantly improve their chances of bypassing alignment with just 25 random augmentations per prompt.
      </li>
      <li><strong>Contribution:</strong> I research and implement different simple data augmentations, including string level and character level. 
        At the same time, I help to check the evaluation metric of the project and do case study as well as labeling the experimental result manually to see how LLM classification align with human evaluation.</li>
	  <div class="linebreak"></div>
	</ul>
  </div>
  <!-- LLM attack -->
  <div class="project">
    <div class="project-title">
      LLM Attack Based on Gradient Method
      <span class="location">UIUC, America</span>
    </div>
    <div class="project-role">
      Advisor: Gagandeep Singh (UIUC Professor), Jason Vega (UIUC Ph.D)
      <span class="date">Jan 2024 - Jun 2024</span>
    </div>
    <ul class="project-details">
      <li><strong>Motivation:</strong> If we can decide the very first output part of LLM generation (which is "<strong><a href="https://arxiv.org/abs/2312.12321">prefilling attack</a></strong>"), we can easily bypass the safety training of LLMs. 
        One of the easiest way to do so is utilizing the Greedy Coordinate Gradient (<strong><a href="https://arxiv.org/abs/2307.15043">GCG</a></strong>) attack to find the "ignore string" to ignore the "ending token" that separates the input prompt and LLM generation.
        Also, we can briefly give an explanation to the random string that is generated by gradient method, compared with random token in GCG attack.
      </li>
      <li><strong>Result:</strong> We attack LLaMA2-7B and LLaMA2-13B with 97% attack successful rate.
      </li>
      <li><strong>Contribution:</strong> I develop the code to find "ignore string" based on <strong>GCG</strong> attack and try different loss functions as well as different place to insert the string.</li>
	  <div class="linebreak"></div>
	</ul>
  </div>
  <!-- Galaxy Federated Learning Framework -->
  <div class="project">
    <div class="project-title">
      Galaxy Federated Learning Framework
      <span class="location">ZJU, China</span>
    </div>
    <div class="project-role">
      Advisor: Chao Wu (ZJU Professor)
      <span class="date">Jun 2022 - Aug 2022</span>
    </div>
    <ul class="project-details">
      <li>Explore a possible method to obtain training data for machine learning from clients with privacy protections </li>
      <li>Help adding functions for monitoring the status of CPU and GPU while running the program</li>
      <li>Debug the data transporting process so that the model can be delivered and trained</li>
  <div class="linebreak"></div>
    </ul>
  </div>
</div>

  <div class="title">
    <a class="title_link" id="publications" href="#publications">Publications</a>
  </div>

  <div class="content publications">
    (* denotes equal contribution)
    <ul>
      <li>
          Jason Vega, <strong>Junsheng Huang</strong>*, Gaokai Zhang*, Hangoo Kang*, Minjia Zhang, Gagandeep Singh. 
          <em><a href="https://arxiv.org/abs/2411.02785">Stochastic Monkeys at Play: Random Augmentations Cheaply Break LLM Safety Alignment.</a></em> 
          Under Review.
      </li>
      <li>
          <strong>Junsheng Huang</strong>, Zhitao He, Sandeep Polisetty, May Fung. 
          <em>Teaching Large Language Models to Handle the Composition of Multiple Problems Simultaneously.</em> 
          Under Review.
      </li>
  </ul>
  </div>

</body>
</html>
